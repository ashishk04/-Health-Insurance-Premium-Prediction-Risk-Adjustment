{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: C:\\Users\\HP\\Downloads\\Yfinance\\1_intro_portfolio_analysis\\code\\insurance.csv\n",
      "OUT_DIR: C:\\Users\\HP\\Downloads\\Yfinance\\1_intro_portfolio_analysis\\code\\outputs\n"
     ]
    }
   ],
   "source": [
    "#### Improved end-to-end script for Healthcare Cost & Insurance Pricing\n",
    "#### - fixes GridSearch for XGBoost\n",
    "#### - uses Pipelines & ColumnTransformer\n",
    "#### - tries log-transform of target\n",
    "#### - compares Linear, DecisionTree, RandomForest, XGBoost\n",
    "#### - KMeans-based risk segmentation and data-driven premium multipliers\n",
    "#### - exports CSVs + saves plots for Power BI\n",
    "\n",
    "# Core Python libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn (ML pipeline)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Business impact simulation\n",
    "import random\n",
    "\n",
    "# Version check (to fix OneHotEncoder sparse vs sparse_output issue)\n",
    "import sklearn\n",
    "from packaging import version\n",
    "\n",
    "# User-specific paths\n",
    "# ---------------------------\n",
    "DATA_PATH = r\"C:\\Users\\HP\\Downloads\\Yfinance\\1_intro_portfolio_analysis\\code\\insurance.csv\"\n",
    "BASE_DIR = os.path.dirname(DATA_PATH)\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 1338\n",
      "After dropping duplicates: 1337\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Load data\n",
    "# ---------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded rows:\", df.shape[0])\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"After dropping duplicates:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count          mean           std        min        50%  \\\n",
      "age       1337.0     39.222139     14.044333       18.0       39.0   \n",
      "sex         1337           NaN           NaN        NaN        NaN   \n",
      "bmi       1337.0     30.663452      6.100468      15.96       30.4   \n",
      "children  1337.0      1.095737      1.205571        0.0        1.0   \n",
      "smoker      1337           NaN           NaN        NaN        NaN   \n",
      "region      1337           NaN           NaN        NaN        NaN   \n",
      "charges   1337.0  13279.121487  12110.359656  1121.8739  9386.1613   \n",
      "\n",
      "                  75%          max  \n",
      "age              51.0         64.0  \n",
      "sex               NaN          NaN  \n",
      "bmi              34.7        53.13  \n",
      "children          2.0          5.0  \n",
      "smoker            NaN          NaN  \n",
      "region            NaN          NaN  \n",
      "charges   16657.71745  63770.42801  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Quick EDA snapshots\n",
    "# ---------------------------\n",
    "print(df.describe(include='all').T[['count','mean','std','min','50%','75%','max']])\n",
    "\n",
    "# Distribution of target\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['charges'], bins=40)\n",
    "plt.title('Charges Distribution (raw)')\n",
    "plt.xlabel('charges')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"charges_hist_raw.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Log-transform distribution (diagnostic)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(np.log1p(df['charges']), bins=40)\n",
    "plt.title('Charges Distribution (log1p)')\n",
    "plt.xlabel('log1p(charges)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"charges_hist_log.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature/target split\n",
    "# ---------------------------\n",
    "X = df.drop(columns=['charges'])\n",
    "y = df['charges'].values\n",
    "\n",
    "# define categorical and numerical columns\n",
    "cat_cols = ['sex','smoker','region']\n",
    "num_cols = ['age','bmi','children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Preprocessing pipelines\n",
    "# ---------------------------\n",
    "cat_transformer = OneHotEncoder(drop='first', sparse_output=False)\n",
    "num_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train/test split\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: metrics function\n",
    "# ---------------------------\n",
    "def metrics_report(y_true, y_pred, label=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{label}: MAE={mae:.1f}, RMSE={rmse:.1f}, R2={r2:.4f}\")\n",
    "    return {'mae': mae, 'rmse': rmse, 'r2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression (raw): MAE=4177.0, RMSE=5956.3, R2=0.8069\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Baseline Linear Regression (raw target)\n",
    "# ---------------------------\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "m_lr = metrics_report(y_test, y_pred_lr, \"LinearRegression (raw)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree (best): MAE=2556.0, RMSE=4296.2, R2=0.8996\n",
      "RandomForest (best): MAE=2399.5, RMSE=4246.0, R2=0.9019\n",
      "XGBRegressor (best): MAE=2463.8, RMSE=4232.5, R2=0.9025\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Tree-based models with GridSearch\n",
    "# ---------------------------\n",
    "# Decision Tree\n",
    "dt_params = {'est__max_depth': [3,5,7,9, None],\n",
    "             'est__min_samples_leaf': [1,5,10]}\n",
    "grid_dt = GridSearchCV(pipe_dt, dt_params, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "m_dt = metrics_report(y_test, y_pred_dt, f\"DecisionTree (best)\")\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {'est__n_estimators':[100,300],\n",
    "             'est__max_depth':[6,10,None],\n",
    "             'est__min_samples_leaf':[1,3,6]}\n",
    "grid_rf = GridSearchCV(pipe_rf, rf_params, cv=4, scoring='r2', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "m_rf = metrics_report(y_test, y_pred_rf, f\"RandomForest (best)\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = {\n",
    "    'est__n_estimators': [100,300],\n",
    "    'est__max_depth': [3,5],\n",
    "    'est__learning_rate': [0.1, 0.05]\n",
    "}\n",
    "grid_xgb = GridSearchCV(pipe_xgb, xgb_params, cv=4, scoring='r2', n_jobs=-1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "m_xgb = metrics_report(y_test, y_pred_xgb, f\"XGBRegressor (best)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression (log-target): MAE=3755.9, RMSE=7197.0, R2=0.7181\n",
      "XGBRegressor (log-target): MAE=2038.5, RMSE=4355.4, R2=0.8968\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Try log1p target (stabilize skew)\n",
    "# ---------------------------\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Linear on log-target\n",
    "pipe_lr_log = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', LinearRegression())\n",
    "])\n",
    "pipe_lr_log.fit(X_train, y_train_log)\n",
    "y_pred_lr_log = pipe_lr_log.predict(X_test)\n",
    "y_pred_lr_log_inv = np.expm1(y_pred_lr_log)\n",
    "m_lr_log = metrics_report(y_test, y_pred_lr_log_inv, \"LinearRegression (log-target)\")\n",
    "\n",
    "# XGBoost on log-target\n",
    "pipe_xgb_log = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('est', XGBRegressor(random_state=42, objective='reg:squarederror', n_jobs=-1))\n",
    "])\n",
    "grid_xgb_log = GridSearchCV(pipe_xgb_log, xgb_params, cv=4, scoring='r2', n_jobs=-1)\n",
    "grid_xgb_log.fit(X_train, y_train_log)\n",
    "best_xgb_log = grid_xgb_log.best_estimator_\n",
    "y_pred_xgb_log = best_xgb_log.predict(X_test)\n",
    "y_pred_xgb_log_inv = np.expm1(y_pred_xgb_log)\n",
    "m_xgb_log = metrics_report(y_test, y_pred_xgb_log_inv, \"XGBRegressor (log-target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model comparison on test set:\n",
      "          model          mae         rmse        r2\n",
      "3       XGB_raw  2463.770826  4232.451958  0.902514\n",
      "2  RandomForest  2399.533283  4245.974394  0.901890\n",
      "1  DecisionTree  2556.031340  4296.198087  0.899555\n",
      "5       XGB_log  2038.498131  4355.418965  0.896767\n",
      "0    Linear_raw  4177.045561  5956.342894  0.806929\n",
      "4    Linear_log  3755.924576  7197.032607  0.718119\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Summarize model comparison\n",
    "# ---------------------------\n",
    "results = pd.DataFrame({\n",
    "    'model': ['Linear_raw','DecisionTree','RandomForest','XGB_raw','Linear_log','XGB_log'],\n",
    "    'mae': [m_lr['mae'], m_dt['mae'], m_rf['mae'], m_xgb['mae'], m_lr_log['mae'], m_xgb_log['mae']],\n",
    "    'rmse':[m_lr['rmse'], m_dt['rmse'], m_rf['rmse'], m_xgb['rmse'], m_lr_log['rmse'], m_xgb_log['rmse']],\n",
    "    'r2':[m_lr['r2'], m_dt['r2'], m_rf['r2'], m_xgb['r2'], m_lr_log['r2'], m_xgb_log['r2']]\n",
    "})\n",
    "print(\"\\nModel comparison on test set:\")\n",
    "print(results.sort_values('rmse'))\n",
    "\n",
    "results.to_csv(os.path.join(OUT_DIR, \"model_comparison.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model by RMSE: XGB_raw\n",
      "\n",
      "Top features:\n",
      "             feature  importance\n",
      "4        smoker_yes    0.830691\n",
      "1               bmi    0.099102\n",
      "0               age    0.044029\n",
      "2          children    0.010777\n",
      "3          sex_male    0.004733\n",
      "7  region_southwest    0.004719\n",
      "5  region_northwest    0.003636\n",
      "6  region_southeast    0.002313\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Feature importances (from chosen tree-based model)\n",
    "# ---------------------------\n",
    "# Determine best model by RMSE\n",
    "best_row = results.loc[results['rmse'].idxmin()]\n",
    "print(\"\\nBest model by RMSE:\", best_row['model'])\n",
    "\n",
    "# Fit preprocessor on full X to get feature names\n",
    "preproc = preprocessor.fit(X)\n",
    "num_names = num_cols\n",
    "cat_ohe = preproc.named_transformers_['cat']\n",
    "cat_names = cat_ohe.get_feature_names_out(cat_cols).tolist()\n",
    "all_feature_names = num_names + cat_names\n",
    "\n",
    "# Pick chosen estimator object\n",
    "if best_row['model'] in ('XGB_raw','XGB_log'):\n",
    "    chosen = best_xgb if best_row['model']=='XGB_raw' else best_xgb_log\n",
    "elif best_row['model']=='RandomForest':\n",
    "    chosen = best_rf\n",
    "elif best_row['model']=='DecisionTree':\n",
    "    chosen = best_dt\n",
    "else:\n",
    "    chosen = best_rf  # fallback\n",
    "\n",
    "if hasattr(chosen.named_steps['est'], 'feature_importances_'):\n",
    "    imp = chosen.named_steps['est'].feature_importances_\n",
    "    feat_imp = pd.DataFrame({'feature': all_feature_names, 'importance': imp})\n",
    "    feat_imp = feat_imp.sort_values('importance', ascending=False)\n",
    "    feat_imp.to_csv(os.path.join(OUT_DIR, \"feature_importances.csv\"), index=False)\n",
    "    print(\"\\nTop features:\\n\", feat_imp.head(10))\n",
    "else:\n",
    "    print(\"Chosen model has no feature_importances_ attribute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Risk segmentation (KMeans) + premium multipliers\n",
    "# ---------------------------\n",
    "df_seg = df.copy()\n",
    "# ensure smoker is binary\n",
    "if df_seg['smoker'].dtype == 'object':\n",
    "    df_seg['smoker_bin'] = df_seg['smoker'].map({'yes':1,'no':0})\n",
    "else:\n",
    "    df_seg['smoker_bin'] = df_seg['smoker']\n",
    "\n",
    "seg_features = df_seg[['age','bmi','smoker_bin']].fillna(0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "seg_scaled = sc.fit_transform(seg_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_seg['risk_cluster'] = kmeans.fit_predict(seg_scaled)\n",
    "\n",
    "cluster_summary = df_seg.groupby('risk_cluster').agg(\n",
    "    n_customers = ('charges','count'),\n",
    "    avg_charges = ('charges','mean'),\n",
    "    median_charges = ('charges','median')\n",
    ").reset_index().sort_values('avg_charges', ascending=False)\n",
    "\n",
    "# Label clusters High/Medium/Low by sorted avg_charges\n",
    "labels = ['High','Medium','Low'][:len(cluster_summary)]\n",
    "cluster_summary['label'] = labels\n",
    "label_map = dict(zip(cluster_summary['risk_cluster'], cluster_summary['label']))\n",
    "df_seg['risk_label'] = df_seg['risk_cluster'].map(label_map)\n",
    "\n",
    "low_avg = cluster_summary[cluster_summary['label']=='Low']['avg_charges'].values[0]\n",
    "cluster_summary['multiplier_vs_low'] = cluster_summary['avg_charges'] / low_avg\n",
    "\n",
    "BASE_PREMIUM = 20000\n",
    "cluster_summary['suggested_premium'] = (BASE_PREMIUM * cluster_summary['multiplier_vs_low']).round(0).astype(int)\n",
    "\n",
    "cluster_summary.to_csv(os.path.join(OUT_DIR, \"cluster_premium_suggestion.csv\"), index=False)\n",
    "df_seg.to_csv(os.path.join(OUT_DIR, \"insurance_with_risk_and_preds.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All artifacts saved to: C:\\Users\\HP\\Downloads\\Yfinance\\1_intro_portfolio_analysis\\code\\outputs\n",
      "Files include: model_comparison.csv, feature_importances.csv (if available), cluster_premium_suggestion.csv, insurance_with_risk_and_preds.csv, and plots.\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Save plots\n",
    "# ---------------------------\n",
    "# Actual vs Pred (best model)\n",
    "if best_row['model']=='XGB_log':\n",
    "    best_preds = y_pred_xgb_log_inv\n",
    "elif best_row['model']=='XGB_raw':\n",
    "    best_preds = y_pred_xgb\n",
    "elif best_row['model']=='RandomForest':\n",
    "    best_preds = y_pred_rf\n",
    "elif best_row['model']=='DecisionTree':\n",
    "    best_preds = y_pred_dt\n",
    "else:\n",
    "    best_preds = y_pred_lr\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, best_preds, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')\n",
    "plt.xlabel('Actual charges')\n",
    "plt.ylabel('Predicted charges')\n",
    "plt.title('Actual vs Predicted (best model)')\n",
    "plt.savefig(os.path.join(OUT_DIR, \"actual_vs_pred_best.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Risk label counts\n",
    "plt.figure(figsize=(6,4))\n",
    "df_seg['risk_label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Count by Risk Label\")\n",
    "plt.xlabel(\"Risk Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"risk_label_counts.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAll artifacts saved to:\", OUT_DIR)\n",
    "print(\"Files include: model_comparison.csv, feature_importances.csv (if available), cluster_premium_suggestion.csv, insurance_with_risk_and_preds.csv, and plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1337\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "# ----------------------------\n",
    "df = pd.read_csv(DATA_PATH).drop_duplicates().reset_index(drop=True)\n",
    "print(\"Rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features / Target\n",
    "# ----------------------------\n",
    "target = \"charges\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].values\n",
    "\n",
    "num_cols = ['age','bmi','children']\n",
    "cat_cols = ['sex','smoker','region']\n",
    "\n",
    "# OneHotEncoder compatibility\n",
    "if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "    cat_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "else:\n",
    "    cat_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', cat_encoder, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Baseline: Linear Regression\n",
    "# ----------------------------\n",
    "pipe_lr = Pipeline([('pre', preprocessor), ('lr', LinearRegression())])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear MAE: 4177.045561036326 XGB MAE: 2463.7708259092815\n"
     ]
    }
   ],
   "source": [
    "# Stronger model: tuned XGBoost (typical go-to)\n",
    "# ----------------------------\n",
    "pipe_xgb = Pipeline([('pre', preprocessor),\n",
    "                     ('xgb', XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))])\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': [100, 300],\n",
    "    'xgb__max_depth': [3, 5],\n",
    "    'xgb__learning_rate': [0.1, 0.05]\n",
    "}\n",
    "grid = GridSearchCV(pipe_xgb, xgb_params, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=0)\n",
    "grid.fit(X_train, y_train)\n",
    "best_xgb = grid.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# Baseline metrics\n",
    "# ----------------------------\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'r2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "m_lr = metrics(y_test, y_pred_lr)\n",
    "m_xgb = metrics(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"Baseline Linear MAE:\", m_lr['mae'], \"XGB MAE:\", m_xgb['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 10% improvement scenario\n",
    "# Option A: if XGB provides ~10% MAE improvement naturally, use it.\n",
    "# Option B: simulate an improvement by shrinking residuals by 10% from baseline.\n",
    "# We'll compute both and show results.\n",
    "# ----------------------------\n",
    "# Prepare test dataframe for reporting\n",
    "X_test_idx = X_test.reset_index(drop=True).copy()\n",
    "test_df = X_test_idx.copy()\n",
    "test_df['actual'] = y_test\n",
    "test_df['pred_baseline'] = y_pred_lr  # linear baseline\n",
    "test_df['pred_xgb'] = y_pred_xgb\n",
    "\n",
    "# Residuals baseline\n",
    "test_df['resid_baseline'] = test_df['actual'] - test_df['pred_baseline']\n",
    "\n",
    "# Simulated improved predictions by shrinking baseline residuals by 10%\n",
    "shrink_factor = 0.9  # residual retained; 10% improvement => residual becomes 0.9*resid\n",
    "test_df['pred_sim10pct'] = test_df['actual'] - shrink_factor * test_df['resid_baseline']\n",
    "# Note: if resid_baseline = actual - pred, then pred_sim = actual - 0.9*resid = pred + 0.1*resid -> closer by 10%\n",
    "\n",
    "# Another simulation: 10% improvement on MAE applied to XGB (if you want)\n",
    "# compute XGB residuals and shrink them similarly\n",
    "test_df['resid_xgb'] = test_df['actual'] - test_df['pred_xgb']\n",
    "test_df['pred_xgb_sim10'] = test_df['actual'] - 0.9 * test_df['resid_xgb']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing & financial simulation parameters\n",
    "# ----------------------------\n",
    "LOADING = 0.20  # 20% loading on predicted claims => premium = pred * (1 + LOADING)\n",
    "BASE_PREMIUM_FACTOR = 1.0 + LOADING\n",
    "\n",
    "def compute_financials(df_preds_col):\n",
    "    \"\"\"\n",
    "    Input: df with columns 'actual' and a predictions column name string\n",
    "    Returns aggregated financial metrics and per-policy series\n",
    "    \"\"\"\n",
    "    pred = df_preds_col\n",
    "    premiums = test_df[pred] * BASE_PREMIUM_FACTOR\n",
    "    claims = test_df['actual']\n",
    "    profit_per_policy = premiums - claims\n",
    "    total_premiums = premiums.sum()\n",
    "    total_claims = claims.sum()\n",
    "    total_profit = profit_per_policy.sum()\n",
    "    loss_ratio = total_claims / total_premiums\n",
    "    return {\n",
    "        'total_premiums': total_premiums,\n",
    "        'total_claims': total_claims,\n",
    "        'total_profit': total_profit,\n",
    "        'loss_ratio': loss_ratio,\n",
    "        'per_policy': pd.DataFrame({\n",
    "            'pred': test_df[pred],\n",
    "            'premium': premiums,\n",
    "            'claim': claims,\n",
    "            'profit': profit_per_policy\n",
    "        })\n",
    "    }\n",
    "\n",
    "# Compute for scenarios\n",
    "scenarios = {}\n",
    "scenarios['baseline_lr'] = compute_financials('pred_baseline')\n",
    "scenarios['xgb'] = compute_financials('pred_xgb')\n",
    "scenarios['sim10_from_lr'] = compute_financials('pred_sim10pct')\n",
    "scenarios['sim10_from_xgb'] = compute_financials('pred_xgb_sim10')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Financial summary saved to outputs. Summary:\n",
      "          scenario  total_premiums  total_claims   total_profit  loss_ratio  \\\n",
      "0     baseline_lr    4.453115e+06  3.824898e+06  628216.955636    0.858926   \n",
      "1             xgb    4.615802e+06  3.824898e+06  790904.363515    0.828653   \n",
      "2   sim10_from_lr    4.466791e+06  3.824898e+06  641893.220590    0.856297   \n",
      "3  sim10_from_xgb    4.613210e+06  3.824898e+06  788311.711065    0.829119   \n",
      "\n",
      "           mae  \n",
      "0  4177.045561  \n",
      "1  2463.770826  \n",
      "2  3759.341005  \n",
      "3  2217.393743  \n",
      "\n",
      "Impact of simulated 10% MAE improvement (from baseline LR):\n",
      " Δ total_profit (improved - baseline) = 13,676.26\n",
      " Δ loss_ratio (baseline - improved) = 0.0026 (reduction in loss ratio)\n",
      "\n",
      "Scaling to 10,000 policies (approx):\n",
      "Estimated Δ profit for 10,000 policies: 510308.39381190436\n",
      "Estimated Δ loss ratio improvement (absolute): 0.00262983076504264\n"
     ]
    }
   ],
   "source": [
    "# Summarize results (per-scenario)\n",
    "# ----------------------------\n",
    "summary_rows = []\n",
    "for name, s in scenarios.items():\n",
    "    summary_rows.append({\n",
    "        'scenario': name,\n",
    "        'total_premiums': s['total_premiums'],\n",
    "        'total_claims': s['total_claims'],\n",
    "        'total_profit': s['total_profit'],\n",
    "        'loss_ratio': s['loss_ratio'],\n",
    "        'mae': mean_absolute_error(test_df['actual'], test_df['pred_baseline'] if name=='baseline_lr' else (test_df['pred_xgb'] if name=='xgb' else (test_df['pred_sim10pct'] if name=='sim10_from_lr' else test_df['pred_xgb_sim10'])))\n",
    "    })\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "summary.to_csv(os.path.join(OUT_DIR, \"financial_simulation_summary.csv\"), index=False)\n",
    "print(\"\\nFinancial summary saved to outputs. Summary:\\n\", summary)\n",
    "\n",
    "# ----------------------------\n",
    "# Quantify impact of 10% MAE improvement\n",
    "# e.g., improvement relative to baseline_lr:\n",
    "# ----------------------------\n",
    "base = scenarios['baseline_lr']\n",
    "improved = scenarios['sim10_from_lr']\n",
    "delta_profit = improved['total_profit'] - base['total_profit']\n",
    "delta_loss_ratio = base['loss_ratio'] - improved['loss_ratio']  # positive means loss ratio reduced\n",
    "print(\"\\nImpact of simulated 10% MAE improvement (from baseline LR):\")\n",
    "print(f\" Δ total_profit (improved - baseline) = {delta_profit:,.2f}\")\n",
    "print(f\" Δ loss_ratio (baseline - improved) = {delta_loss_ratio:.4f} (reduction in loss ratio)\")\n",
    "\n",
    "# Scale to a portfolio of 10000 policies (if this test sample is representative)\n",
    "scale_factor = 10000 / len(test_df)\n",
    "print(\"\\nScaling to 10,000 policies (approx):\")\n",
    "print(\"Estimated Δ profit for 10,000 policies:\", delta_profit * scale_factor)\n",
    "print(\"Estimated Δ loss ratio improvement (absolute):\", delta_loss_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-policy table exported for Power BI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to outputs. Done.\n"
     ]
    }
   ],
   "source": [
    "# Export Power BI–ready files\n",
    "# ----------------------------\n",
    "# Merge per-policy columns into a single table for Power BI\n",
    "output_table = test_df.copy()\n",
    "output_table['premium_baseline'] = output_table['pred_baseline'] * BASE_PREMIUM_FACTOR\n",
    "output_table['premium_xgb'] = output_table['pred_xgb'] * BASE_PREMIUM_FACTOR\n",
    "output_table['premium_sim10'] = output_table['pred_sim10pct'] * BASE_PREMIUM_FACTOR\n",
    "output_table['profit_baseline'] = output_table['premium_baseline'] - output_table['actual']\n",
    "output_table['profit_xgb'] = output_table['premium_xgb'] - output_table['actual']\n",
    "output_table['profit_sim10'] = output_table['premium_sim10'] - output_table['actual']\n",
    "\n",
    "output_table.to_csv(os.path.join(OUT_DIR, \"powerbi_insurance_pricing_table.csv\"), index=False)\n",
    "print(\"Per-policy table exported for Power BI.\")\n",
    "\n",
    "# Save a few diagnostic plots\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(test_df['actual'] - test_df['pred_baseline'], bins=40)\n",
    "plt.title(\"Residuals: actual - baseline_pred\")\n",
    "plt.savefig(os.path.join(OUT_DIR, \"residuals_baseline_hist.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(test_df['actual'] - test_df['pred_sim10pct'], bins=40)\n",
    "plt.title(\"Residuals after 10% shrink (simulated)\")\n",
    "plt.savefig(os.path.join(OUT_DIR, \"residuals_sim10_hist.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(test_df['pred_baseline'], test_df['actual'], alpha=0.5, label='baseline')\n",
    "plt.scatter(test_df['pred_xgb'], test_df['actual'], alpha=0.5, label='xgb')\n",
    "plt.legend()\n",
    "plt.title(\"Predicted vs Actual (baseline vs xgb)\")\n",
    "plt.savefig(os.path.join(OUT_DIR, \"pred_vs_actual_compare.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved to outputs. Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Insurance Charges: $ 44593.98\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 9: Predict charges with user input\n",
    "# ================================\n",
    "\n",
    "# Refit best model (let's assume XGBoost performed best)\n",
    "best_model = pipe_xgb.fit(X, y)\n",
    "\n",
    "# Function to predict insurance charges\n",
    "def predict_charges_userinput():\n",
    "    \"\"\"\n",
    "    Ask user for input and predict insurance charges.\n",
    "    \"\"\"\n",
    "    # Take inputs from user\n",
    "    age = int(input(\"Enter Age: \"))\n",
    "    bmi = float(input(\"Enter BMI: \"))\n",
    "    children = int(input(\"Enter number of Children: \"))\n",
    "    sex = input(\"Enter Sex (male/female): \").lower()\n",
    "    smoker = input(\"Smoker? (yes/no): \").lower()\n",
    "    region = input(\"Enter Region (northeast/northwest/southeast/southwest): \").lower()\n",
    "    \n",
    "    # Create dataframe\n",
    "    input_data = pd.DataFrame([{\n",
    "        \"age\": age,\n",
    "        \"bmi\": bmi,\n",
    "        \"children\": children,\n",
    "        \"sex\": sex,\n",
    "        \"smoker\": smoker,\n",
    "        \"region\": region\n",
    "    }])\n",
    "    \n",
    "    # Predict charges\n",
    "    prediction = best_model.predict(input_data)[0]\n",
    "    print(\"\\nPredicted Insurance Charges: $\", round(prediction, 2))\n",
    "\n",
    "# Run the function\n",
    "predict_charges_userinput()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find weight or importance of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
